{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from segmentation_models import PSPNet\n",
    "from segmentation_models import FPN\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models.segmentation_models.backbones import get_preprocessing\n",
    "\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import spacexyz\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_gt = True\n",
    "# path_to_data = \"/scratch2/peilun/relabeled_data/new_val_images\"\n",
    "\n",
    "# if have_gt:\n",
    "#     path_to_label = \"/scratch2/peilun/val_labels\"\n",
    "\n",
    "path_to_data = \"/scratch2/peilun/SpaceXYZ/dr/1\"\n",
    "data_files = spacexyz.path2filelist(path_to_data)\n",
    "\n",
    "path_to_label = \"/scratch2/peilun/SpaceXYZ/dr/2\"\n",
    "label_files = spacexyz.path2filelist(path_to_label)\n",
    "\n",
    "path_to_model = '/scratch2/peilun/SpaceXYZ/Unet_epoch_10.h5'\n",
    "\n",
    "num_classes = 1+6\n",
    "\n",
    "input_size = (512, 512, 3)\n",
    "output_size = (512, 512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "############# Read in files ########################\n",
    "####################################################\n",
    "\n",
    "data_files = spacexyz.path2filelist(path_to_data)\n",
    "label_files = spacexyz.path2filelist(path_to_label)\n",
    "\n",
    "data_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "n_samples = len(data_files)\n",
    "\n",
    "print('Num of images: ', n_samples)\n",
    "\n",
    "print(\"reading in \", n_samples, \" samples...\")\n",
    "X_ = np.zeros([n_samples, *input_size]).astype(np.uint8)\n",
    "y_ = np.zeros([n_samples, *input_size[:2]]).astype(np.uint8)\n",
    "remember_size = np.zeros([n_samples, 2])\n",
    "for i in range(n_samples):\n",
    "    print(i, end='. ')\n",
    "    image = cv2.imread(join(path_to_data, data_files[i]))\n",
    "    remember_size[i, :] = image.shape[:2]\n",
    "    X_[i,:,:,:] = cv2.resize(image, input_size[:2])\n",
    "    if have_gt:\n",
    "        label = cv2.imread(join(path_to_label, label_files[i]))\n",
    "        y_[i,:,:] = cv2.resize(label[:,:,0], output_size[:2], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes=7, dtype='float32')\n",
    "remember_size = remember_size.astype(np.int64)\n",
    "assert(remember_size.shape[0] == n_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################\n",
    "############# Load model ###########################\n",
    "####################################################\n",
    "\n",
    "print(\"Loading training model...\")\n",
    "model = keras.models.load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "############# Perform inference ####################\n",
    "####################################################\n",
    "print(\"Performing inference...\")\n",
    "pred = model.predict(X_, batch_size=None, verbose=1, steps=None)\n",
    "\n",
    "####################################################\n",
    "############# Resize to original ###################\n",
    "####################################################\n",
    "\n",
    "\n",
    "####################################################\n",
    "############# Save segmentation results ############\n",
    "####################################################\n",
    "\n",
    "# pred_labels = []\n",
    "# for i in range(ind.shape[0]):\n",
    "# #     ind_original_size =  cv2.resize(ind[i,:,:], tuple(remember_size[i,:2]), interpolation=cv2.INTER_LINEAR)\n",
    "#     ind_original_size =  cv2.resize(ind[i,:,:], tuple(remember_size[i,:2]))\n",
    "#     pred_labels.append(ind_original_size)\n",
    "    \n",
    "# # todo\n",
    "# h5f = h5py.File('oxygen_plans_new.h5', 'w')\n",
    "# h5f.create_dataset('oxygen_plans', data=pred)\n",
    "# h5f.close()\n",
    "\n",
    "# # read in results\n",
    "# h5f = h5py.File('oxygen_plans.h5','r')\n",
    "# b = h5f['oxygen_plans'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "h5f = h5py.File('eko_result.h5', 'w')\n",
    "h5f.create_dataset('eko_result', data=pred)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import skimage\n",
    "\n",
    "ind = spacexyz.onehot2ind(pred)\n",
    "print(ind.shape)\n",
    "\n",
    "path_to_data = \"/scratch2/peilun/SpaceXYZ/dr/1\"\n",
    "data_files = spacexyz.path2filelist(path_to_data)\n",
    "data_files.sort()\n",
    "\n",
    "path_to_label = \"/scratch2/peilun/SpaceXYZ/dr/2\"\n",
    "label_files = spacexyz.path2filelist(path_to_label)\n",
    "label_files.sort()\n",
    "\n",
    "for k in range(n_samples):\n",
    "    image = cv2.imread(join(path_to_data, data_files[k]))\n",
    "#     label = ind[k,:,:]\n",
    "    size = image.shape\n",
    "    label = cv2.imread(join(path_to_label, label_files[k]))\n",
    "    label = label[:,:,0]\n",
    "    print(label.max())\n",
    "    segmap = label.astype(np.int32)\n",
    "    label = skimage.transform.resize(label, size[:2], order=0, mode='reflect')\n",
    "    segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape[:2], nb_classes=num_classes)\n",
    "#     plt.imshow(segmap.draw_on_image(image))\n",
    "    s_name = './final_overlay_gt/'+str(k)+'.png'\n",
    "    cv2.imwrite(s_name,segmap.draw_on_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pred[0,:,:,1])\n",
    "# plt.imsave('wall.png', pred[0,:,:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=83\n",
    "label = pred_labels[k]\n",
    "segmap = label.astype(np.int32)\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=(512, 512), nb_classes=1+6)\n",
    "# plt.imshow(segmap.draw_on_image(X_[k,:,:,:]))\n",
    "plt.imshow(segmap.draw_on_image(t_image))\n",
    "cv2.imwrite('messigray.png',segmap.draw_on_image(X_[k,:,:,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
